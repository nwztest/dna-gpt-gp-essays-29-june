{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT3.5 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "In this notebook, I generate essays from GPT3.5 (aka ChatGPT's model). The AI-generated essays will not be solely composed of those generated from GPT3.5, however. For each regeneration engine, we will generate essays using that engine for testing.\n",
    "Fun fact: This is the first batch of AI-generated essays!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Helper functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General helper library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key_path = os.getcwd() + 'key path here'\n",
    "\n",
    "system_prompt = \"You are an exemplary Singapore Junior College student that writes essays. When given a prompt, you will write only an essay. You will write as many words as you can. You will not write headings for the essay. \"\n",
    "# neo wee zen's very own essay generation function\n",
    "def get_chatgpt_essay_response(prompt_text, max_tokens=3500):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": system_prompt},\n",
    "        {\"role\":\"user\", \"content\": prompt_text + \" Your essay should not be less than 1000 words.\"},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "                model = \"gpt-3.5-turbo\",\n",
    "                messages = messages,\n",
    "                temperature = 1,\n",
    "                max_tokens = max_tokens\n",
    "    )\n",
    "    return response # ['choices'][0]['message']['content']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "In this section, we'll set up the essay dictionaries. If the AI-generated essay file is not yet created, then it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd() + \"/../../essay_gpt35_2.json\", 'r') as gpt35_essay_file:\n",
    "    gpt35_dict = json.load(gpt35_essay_file)\n",
    "    \n",
    "with open(os.getcwd() + \"/../../essay_human_original.json\", 'r') as human_essay_file:\n",
    "    human_json = json.load(human_essay_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug: clears the GPT 3.5 dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt35_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the GPT 3.5 dictionary is empty (i.e. JSON file is empty), then it will be initialised as a defaultdict, which has a default of a defaultdict, which has a default of a list. This is to ensure that I am able to easily set the values to each of the types of essays as dictionaries, and the values of each of the websites as lists of essay dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_list_dict():\n",
    "    return defaultdict(list)\n",
    "\n",
    "print(gpt35_dict)\n",
    "if not gpt35_dict:\n",
    "    gpt35_dict = defaultdict(default_list_dict)\n",
    "\n",
    "# gpt35_json['urgh']['testing'] = 'thing'\n",
    "# print(gpt35_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a test to generate the same structure of the human essay in the GPT 3.5 essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all prompts in list\n",
    "prompt_list = []\n",
    "\n",
    "for type_of_essay in human_json:\n",
    "    for website in human_json[type_of_essay]:\n",
    "        for essay_dict in human_json[type_of_essay][website]:\n",
    "            prompt_list.append(essay_dict['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type_of_essay in human_json:\n",
    "#     for website in human_json[type_of_essay]:\n",
    "#         for essay_dict in human_json[type_of_essay][website]:\n",
    "#             gpt35_dict[type_of_essay][website].append({\n",
    "#                 'website': essay_dict['website'],\n",
    "#                 'prompt': essay_dict['prompt'],\n",
    "#                 'response': 'this is chatgpt speaking'\n",
    "#             })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If gpt35_dict is a defaultdict, it is converted back to a dict so that printing it actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt35_dict = dict(gpt35_dict)\n",
    "\n",
    "# for type_of_essay in gpt35_dict:\n",
    "#     gpt35_dict[type_of_essay] = dict(gpt35_dict[type_of_essay])\n",
    "\n",
    "# # print(gpt35_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a test generation of a single essay by GPT 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prompt = prompt_list[random.randint(0, len(prompt_list) - 1)]\n",
    "print(random_prompt)\n",
    "\n",
    "\n",
    "test_gpt35_essay_response = get_chatgpt_essay_response(random_prompt)\n",
    "print(test_gpt35_essay_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_gpt35_essay_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code saves each GPT 3.5-generated essay into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for type_of_essay in human_json:\n",
    "    for website in human_json[type_of_essay]:\n",
    "        for essay_dict in human_json[type_of_essay][website]:\n",
    "            if count <= 8: \n",
    "                count += 1\n",
    "                continue\n",
    "            print(\"generating\", count, \"out of\", len(prompt_list))\n",
    "            print(essay_dict['prompt'])\n",
    "            count += 1\n",
    "            gpt35_response_dict = get_chatgpt_essay_response(prompt_text=essay_dict['prompt'])\n",
    "            gpt35_dict[type_of_essay][website].append({\n",
    "                'website': essay_dict['website'],\n",
    "                'prompt': essay_dict['prompt'],\n",
    "                'response': gpt35_response_dict['choices'][0]['message']['content']\n",
    "            })\n",
    "            print(\"generated!\\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(gpt35_dict, indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing general trends in AI-generated essays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I find the highest, lowest, 25th and 75th percentile of essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "ai_essay_word_count_list = []\n",
    "\n",
    "for type_of_essay in gpt35_dict:\n",
    "    for website in gpt35_dict[type_of_essay]:\n",
    "        for essay_dict in gpt35_dict[type_of_essay][website]:\n",
    "            count += 1\n",
    "            word_count = len(essay_dict['response'].split())\n",
    "            ai_essay_word_count_list.append(word_count)\n",
    "            \n",
    "ai_essay_word_count_list.sort()\n",
    "print(ai_essay_word_count_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to JSON file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I write to the essay generation JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd() + \"/../../essay_gpt35_2.json\", 'w') as gpt35_essay_file:\n",
    "    json.dump(gpt35_dict, gpt35_essay_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
